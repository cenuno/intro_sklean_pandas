{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn_pandas import (\n",
    "    DataFrameMapper, \n",
    "    FunctionTransformer\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris[\"data\"]\n",
    "y = iris[\"target\"]\n",
    "feature_names = [col.replace(\" \", \"_\").replace(\"_(cm)\", \"\") \n",
    "                 for col in (iris[\"feature_names\"] + [\"species\"])]\n",
    "class_names = {0.0: \"setosa\", 1.0: \"versicolor\", 2.0: \"virginica\"}\n",
    "\n",
    "# convert to data frame purely for showing the data\n",
    "iris_df = pd.DataFrame(np.column_stack((X, y.reshape(-1, 1)))\n",
    "                       , columns=feature_names)\n",
    "\n",
    "# convert species from numeric to categorical\n",
    "iris_df[\"species\"] = iris_df[\"species\"].map(class_names)\n",
    "\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For educational purposes only, let's replace some values with `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random number generator\n",
    "random.seed(2019)\n",
    "\n",
    "# generate list of random integers \n",
    "random_ints = [random.randrange(0, len(iris_df)) for _ in range(20)]\n",
    "\n",
    "# for these random index values, replace their real values with NaN\n",
    "iris_df.loc[random_ints, \"sepal_length\"] = np.nan\n",
    "iris_df.loc[random_ints, \"sepal_width\"] = np.nan\n",
    "\n",
    "# manually force the first \"sepal_width\" value to also be NaN\n",
    "iris_df.loc[0, \"sepal_width\"] = np.nan\n",
    "\n",
    "iris_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create function to identify records that have `NaN` values\n",
    "\n",
    "This will help us pick up on whether or not having a `NaN` value is helpful information in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_missing(x):\n",
    "    \"\"\"IDs records that contain missing (NaN) values\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not create an object that imputes median values\n",
    "\n",
    "Unfortunately, `sklearn_pandas` is still under development. The usage of the following:\n",
    "\n",
    "```python\n",
    "impute_median = SimpleImputer(missing_values=np.nan, strategy=\"median\")\n",
    "```\n",
    "\n",
    "inside `DataFrameMapper` will result in all columns that use the `impute_median` transformer to have the same value.\n",
    "\n",
    "Instead, do a gut check by manually printing out the median values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Median value for sepal length: {iris_df['sepal_length'].median()}\")\n",
    "print(f\"Median value for sepal width: {iris_df['sepal_width'].median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store preprocessing steps in one object\n",
    "\n",
    "![kid transformer](visuals/transformer.gif)\n",
    "\n",
    "We'll store these steps in a `DataFrameMapper` object. A `DataFrameMapper` maps `pandas` data frame column subsets to their own transformations. This is abstraction is useful since we'll always be applying the same preprocessing steps to both our training and testing sets.\n",
    "\n",
    "The key here is we need to specify a specific column, pass it's \"transformer\" (i.e. `SimpleImputer`, `OneHotEncoder`, `StandardScaler`), and determinie if the transformation belongs in it's own new column or if it's more appropriate for the transformed column to overwrite the input column.\n",
    "\n",
    "Here, we'll create `mapper` object to do the following:\n",
    "\n",
    "* flag which records contain `NaN` values in the `sepal_length` feature;\n",
    "* impute the median value for `NaN` values in the `sepal_length` feature;\n",
    "* flag which records contain `NaN` values in the `sepal_width` feature;\n",
    "* impute the median value for `NaN` values in the `sepal_width` feature; and\n",
    "* return all other columns - `petal_length` & `petal_width` - as is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper(features=[\n",
    "    ([\"sepal_length\"], FunctionTransformer(is_missing), {\"alias\": \"sepal_length_missing\"}),\n",
    "    ([\"sepal_length\"], SimpleImputer(missing_values=np.nan, strategy=\"median\")),\n",
    "    ([\"sepal_width\"], FunctionTransformer(is_missing), {\"alias\": \"sepal_width_missing\"}),\n",
    "    ([\"sepal_width\"], SimpleImputer(missing_values=np.nan, strategy=\"median\")),\n",
    "],\n",
    "                         default=None,\n",
    "                         df_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just like a model object, \n",
    "# we'll fit and transform the DataFrameMapper object onto our data\n",
    "mapper.fit(iris_df).transform(iris_df).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the 9th record in both columns contains a value of `1`. This algins with the output of `iris_df.head(10)`, with both values in `sepal_length` and `sepal_width` containing `NaN` values.\n",
    "\n",
    "The use of our custom function was honored and bug-free, as only the first record in `sepal_width_missing` has a value of `1` and `sepal_length_missing` has a value of `0`.\n",
    "\n",
    "All records in the `petal_length`, `petal_width` and `species` columns are returned with no transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's take this up a level by performing `train_test_split` before any preprocessing and build a `DecisionTreeClassifier` model to classify which species a flower is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_df.drop(\"species\", axis=1),\n",
    "                                                    iris_df[\"species\"],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=2019,\n",
    "                                min_samples_leaf=30,\n",
    "                                criterion=\"gini\",\n",
    "                                min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"dataprep\", mapper),\n",
    "    (\"model\", dt_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit `X_train` and `y_train` onto the `pipe` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `pipe` object to make predictions on `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the first 10 predictions of our multi-class classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "* Make multi class ROC Curve: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
